模型加载成功！
词汇表大小: 3000000
[03/13 14:53:03 pysgg]: Using 1 GPUs
[03/13 14:53:03 pysgg]: Namespace(config_file='', local_rank=0, num_workers=4, output_dir='checkpoints/sgdet-BGNNPredictor/2025-03-13_14', dataset_name='VG_stanford', dataset_name_test='VG_stanford_test', dataset_name_val='VG_stanford_val', img_dir='datasets/vg/stanford_spilt/VG_100k_images', glove_dir='datasets/vg/stanford_spilt/glove', word2vec_dir='datasets/vg/stanford_spilt/word2vec', roidb_file='datasets/vg/VG-SGG-with-attri.h5', dict_file='datasets/vg/VG-SGG-dicts-with-attri.json', image_file='datasets/vg/image_data.json', debug=True, train_pre_batch=3, test_pre_batch=1, max_iter=1000, size_divisbility=32, base_lr=0.008, weight_decay=1e-05, bias_factor=1.0, weight_decay_bias=0.0, momentum=0.9, pretrained_detection_ckpt='checkpoints/detection/pretrained_faster_rcnn/vg_faster_det.pth', checkpoint_period=500, skip_test=False, opts=[], res_in_channels=64, res_out_channels=256, backbone_out_channels=256, box_head_num_class=151, device='cuda', distributed=False)
[03/13 14:53:03 pysgg]: #################### Start initializing dataset & dataloader ####################
[03/13 14:53:22 dataset]: using resampling method:bilvl
[03/13 14:53:22 dataset]: generate the repeat dict according to hyper_param on the fly
[03/13 14:53:22 dataset]: global repeat factor: 0.012;  
[03/13 14:53:22 dataset]: drop rate: 0.4;
[03/13 14:53:25 dataset]: using resampling method:bilvl
[03/13 14:53:25 dataset]: generate the repeat dict according to hyper_param on the fly
[03/13 14:53:25 dataset]: global repeat factor: 0.012;  
[03/13 14:53:25 dataset]: drop rate: 0.4;
[03/13 14:53:27 utils.miscellaneous]: Saving labels mapping into checkpoints/sgdet-BGNNPredictor/2025-03-13_14/labels.json
/home/p_zhuzy/miniconda3/envs/pysgg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[03/13 14:53:28 pysgg]: the nums of train loader is 1000
[03/13 14:53:28 pysgg]: the nums of val loader is 600
[03/13 14:53:28 pysgg]: #################### end dataloader ####################
[03/13 14:53:28 pysgg]: #################### prepare training ####################
[03/13 14:53:33 dataset]: using resampling method:bilvl
[03/13 14:53:33 dataset]: generate the repeat dict according to hyper_param on the fly
[03/13 14:53:33 dataset]: global repeat factor: 0.012;  
[03/13 14:53:33 dataset]: drop rate: 0.4;
[03/13 14:53:36 dataset]: using resampling method:bilvl
[03/13 14:53:36 dataset]: generate the repeat dict according to hyper_param on the fly
[03/13 14:53:36 dataset]: global repeat factor: 0.012;  
[03/13 14:53:36 dataset]: drop rate: 0.4;
Get relation class frequency distribution on dataset.
  0%|          | 0/41459 [00:00<?, ?it/s]  1%|          | 425/41459 [00:00<00:09, 4241.89it/s]  2%|▏         | 850/41459 [00:00<00:09, 4146.94it/s]  3%|▎         | 1265/41459 [00:00<00:09, 4045.23it/s]  4%|▍         | 1670/41459 [00:00<00:10, 3963.64it/s]  5%|▌         | 2138/41459 [00:00<00:09, 4211.78it/s]  6%|▌         | 2561/41459 [00:00<00:09, 3920.56it/s]  7%|▋         | 2957/41459 [00:00<00:10, 3777.91it/s]  8%|▊         | 3359/41459 [00:00<00:09, 3849.15it/s]  9%|▉         | 3756/41459 [00:00<00:09, 3883.76it/s] 10%|█         | 4170/41459 [00:01<00:09, 3958.64it/s] 11%|█         | 4584/41459 [00:01<00:09, 4012.25it/s] 12%|█▏        | 4998/41459 [00:01<00:09, 4048.85it/s] 13%|█▎        | 5404/41459 [00:01<00:08, 4040.83it/s] 14%|█▍        | 5809/41459 [00:01<00:08, 3982.62it/s] 15%|█▍        | 6208/41459 [00:01<00:08, 3945.05it/s] 16%|█▌        | 6603/41459 [00:01<00:08, 3918.69it/s] 17%|█▋        | 6996/41459 [00:01<00:08, 3900.61it/s] 18%|█▊        | 7387/41459 [00:01<00:08, 3886.47it/s] 19%|█▉        | 7788/41459 [00:01<00:08, 3922.45it/s] 20%|█▉        | 8203/41459 [00:02<00:08, 3989.41it/s] 21%|██        | 8624/41459 [00:02<00:08, 4052.33it/s] 22%|██▏       | 9041/41459 [00:02<00:07, 4085.09it/s] 23%|██▎       | 9470/41459 [00:02<00:07, 4143.34it/s] 24%|██▍       | 9885/41459 [00:02<00:07, 4125.90it/s] 25%|██▍       | 10301/41459 [00:02<00:07, 4134.50it/s] 26%|██▌       | 10732/41459 [00:02<00:07, 4185.11it/s] 27%|██▋       | 11151/41459 [00:02<00:07, 4136.09it/s] 28%|██▊       | 11582/41459 [00:02<00:07, 4186.84it/s] 29%|██▉       | 12001/41459 [00:02<00:07, 4185.58it/s] 30%|██▉       | 12420/41459 [00:03<00:06, 4178.93it/s] 31%|███       | 12841/41459 [00:03<00:06, 4187.12it/s] 32%|███▏      | 13260/41459 [00:03<00:06, 4159.10it/s] 33%|███▎      | 13692/41459 [00:03<00:06, 4204.30it/s] 34%|███▍      | 14113/41459 [00:03<00:06, 4156.47it/s] 35%|███▌      | 14530/41459 [00:03<00:06, 4157.94it/s] 36%|███▌      | 14960/41459 [00:03<00:06, 4197.46it/s] 37%|███▋      | 15380/41459 [00:03<00:06, 4160.03it/s] 38%|███▊      | 15807/41459 [00:03<00:06, 4190.21it/s] 39%|███▉      | 16227/41459 [00:03<00:06, 4173.46it/s] 40%|████      | 16645/41459 [00:04<00:05, 4169.04it/s] 41%|████      | 17069/41459 [00:04<00:05, 4189.34it/s] 42%|████▏     | 17488/41459 [00:04<00:05, 4174.68it/s] 43%|████▎     | 17919/41459 [00:04<00:05, 4213.99it/s] 44%|████▍     | 18341/41459 [00:04<00:05, 4161.83it/s] 45%|████▌     | 18758/41459 [00:04<00:05, 4155.20it/s] 46%|████▋     | 19179/41459 [00:04<00:05, 4170.12it/s] 47%|████▋     | 19597/41459 [00:04<00:05, 4136.76it/s] 48%|████▊     | 20027/41459 [00:04<00:05, 4183.85it/s] 49%|████▉     | 20446/41459 [00:04<00:05, 4178.77it/s] 50%|█████     | 20864/41459 [00:05<00:04, 4154.67it/s] 51%|█████▏    | 21286/41459 [00:05<00:04, 4172.64it/s] 52%|█████▏    | 21704/41459 [00:05<00:04, 4153.49it/s] 53%|█████▎    | 22130/41459 [00:05<00:04, 4184.49it/s] 54%|█████▍    | 22549/41459 [00:05<00:04, 4150.54it/s] 55%|█████▌    | 22965/41459 [00:05<00:04, 4148.78it/s] 56%|█████▋    | 23395/41459 [00:05<00:04, 4191.05it/s] 57%|█████▋    | 23815/41459 [00:05<00:04, 4145.77it/s] 58%|█████▊    | 24242/41459 [00:05<00:04, 4179.99it/s] 59%|█████▉    | 24661/41459 [00:06<00:04, 4165.10it/s] 60%|██████    | 25078/41459 [00:06<00:03, 4154.10it/s] 61%|██████▏   | 25497/41459 [00:06<00:03, 4163.91it/s] 63%|██████▎   | 25914/41459 [00:06<00:03, 4121.71it/s] 64%|██████▎   | 26327/41459 [00:06<00:03, 4036.38it/s] 64%|██████▍   | 26732/41459 [00:06<00:03, 3979.70it/s] 65%|██████▌   | 27131/41459 [00:06<00:03, 3939.65it/s] 66%|██████▋   | 27526/41459 [00:06<00:03, 3914.10it/s] 67%|██████▋   | 27918/41459 [00:06<00:03, 3894.07it/s] 68%|██████▊   | 28308/41459 [00:06<00:03, 3879.56it/s] 69%|██████▉   | 28728/41459 [00:07<00:03, 3973.24it/s] 70%|███████   | 29134/41459 [00:07<00:03, 3996.00it/s] 71%|███████▏  | 29562/41459 [00:07<00:02, 4079.20it/s] 72%|███████▏  | 29972/41459 [00:07<00:02, 4085.28it/s] 73%|███████▎  | 30394/41459 [00:07<00:02, 4124.85it/s] 74%|███████▍  | 30808/41459 [00:07<00:02, 4126.80it/s] 75%|███████▌  | 31221/41459 [00:07<00:02, 4126.07it/s] 76%|███████▋  | 31648/41459 [00:07<00:02, 4167.35it/s] 77%|███████▋  | 32065/41459 [00:07<00:02, 4129.74it/s] 78%|███████▊  | 32488/41459 [00:07<00:02, 4159.49it/s] 79%|███████▉  | 32910/41459 [00:08<00:02, 4175.90it/s] 80%|████████  | 33328/41459 [00:08<00:01, 4142.32it/s] 81%|████████▏ | 33756/41459 [00:08<00:01, 4183.24it/s] 82%|████████▏ | 34175/41459 [00:08<00:01, 4171.35it/s] 83%|████████▎ | 34598/41459 [00:08<00:01, 4188.42it/s] 84%|████████▍ | 35017/41459 [00:08<00:01, 4163.95it/s] 85%|████████▌ | 35434/41459 [00:08<00:01, 4143.31it/s] 87%|████████▋ | 35865/41459 [00:08<00:01, 4192.27it/s] 88%|████████▊ | 36285/41459 [00:08<00:01, 4151.37it/s] 89%|████████▊ | 36704/41459 [00:08<00:01, 4160.52it/s] 90%|████████▉ | 37128/41459 [00:09<00:01, 4183.12it/s] 91%|█████████ | 37547/41459 [00:09<00:00, 4148.11it/s] 92%|█████████▏| 37977/41459 [00:09<00:00, 4192.68it/s] 93%|█████████▎| 38397/41459 [00:09<00:00, 4156.18it/s] 94%|█████████▎| 38817/41459 [00:09<00:00, 4167.22it/s] 95%|█████████▍| 39234/41459 [00:09<00:00, 4135.59it/s] 96%|█████████▌| 39648/41459 [00:09<00:00, 4086.76it/s] 97%|█████████▋| 40057/41459 [00:09<00:00, 4010.80it/s] 98%|█████████▊| 40459/41459 [00:09<00:00, 3928.25it/s] 99%|█████████▊| 40853/41459 [00:09<00:00, 3851.70it/s]100%|█████████▉| 41262/41459 [00:10<00:00, 3918.53it/s]100%|██████████| 41459/41459 [00:10<00:00, 4088.36it/s]
  0%|          | 0/5284 [00:00<?, ?it/s] 14%|█▍        | 757/5284 [00:00<00:00, 7565.82it/s] 31%|███       | 1650/5284 [00:00<00:00, 8361.44it/s] 47%|████▋     | 2487/5284 [00:00<00:00, 7335.84it/s] 63%|██████▎   | 3315/5284 [00:00<00:00, 7676.60it/s] 77%|███████▋  | 4094/5284 [00:00<00:00, 7383.18it/s] 92%|█████████▏| 4840/5284 [00:00<00:00, 7055.10it/s]100%|██████████| 5284/5284 [00:00<00:00, 7260.56it/s]
  0%|          | 0/41459 [00:00<?, ?it/s]  3%|▎         | 1208/41459 [00:00<00:03, 12073.45it/s]  6%|▌         | 2424/41459 [00:00<00:03, 12112.98it/s]  9%|▉         | 3636/41459 [00:00<00:03, 11641.66it/s] 12%|█▏        | 4886/41459 [00:00<00:03, 11971.06it/s] 15%|█▍        | 6132/41459 [00:00<00:02, 12144.15it/s] 18%|█▊        | 7359/41459 [00:00<00:02, 12183.26it/s] 21%|██        | 8581/41459 [00:00<00:02, 12194.41it/s] 24%|██▍       | 9851/41459 [00:00<00:02, 12353.33it/s] 27%|██▋       | 11087/41459 [00:00<00:02, 12237.85it/s] 30%|██▉       | 12328/41459 [00:01<00:02, 12289.49it/s] 33%|███▎      | 13558/41459 [00:01<00:02, 12273.72it/s] 36%|███▌      | 14786/41459 [00:01<00:02, 12175.15it/s] 39%|███▊      | 16053/41459 [00:01<00:02, 12322.37it/s] 42%|████▏     | 17286/41459 [00:01<00:01, 12300.06it/s] 45%|████▍     | 18527/41459 [00:01<00:01, 12329.80it/s] 48%|████▊     | 19761/41459 [00:01<00:01, 12329.95it/s] 51%|█████     | 20995/41459 [00:01<00:01, 12272.09it/s] 54%|█████▎    | 22263/41459 [00:01<00:01, 12391.55it/s] 57%|█████▋    | 23503/41459 [00:01<00:01, 12275.27it/s] 60%|█████▉    | 24757/41459 [00:02<00:01, 12352.61it/s] 63%|██████▎   | 26019/41459 [00:02<00:01, 12430.82it/s] 66%|██████▌   | 27263/41459 [00:02<00:01, 12319.18it/s] 69%|██████▉   | 28535/41459 [00:02<00:01, 12437.21it/s] 72%|███████▏  | 29780/41459 [00:02<00:00, 12381.28it/s] 75%|███████▍  | 31030/41459 [00:02<00:00, 12414.27it/s] 78%|███████▊  | 32272/41459 [00:02<00:00, 12376.76it/s] 81%|████████  | 33510/41459 [00:02<00:00, 12309.82it/s] 84%|████████▍ | 34784/41459 [00:02<00:00, 12436.67it/s] 87%|████████▋ | 36028/41459 [00:02<00:00, 12293.56it/s] 90%|████████▉ | 37281/41459 [00:03<00:00, 12362.26it/s] 93%|█████████▎| 38533/41459 [00:03<00:00, 12408.93it/s] 96%|█████████▌| 39775/41459 [00:03<00:00, 12385.45it/s] 99%|█████████▉| 41014/41459 [00:03<00:00, 12252.94it/s]100%|██████████| 41459/41459 [00:03<00:00, 12282.65it/s]
🔹 直接加载 PyTorch 词向量: datasets/vg/stanford_spilt/word2vec/GoogleNews-vectors-negative300.300d.pt
🔹 加载的词向量维度: 300
🔹 '__background__' -> '__background__' (尝试匹配)
 无法找到 '__background__' 的词向量
🔹 直接加载 PyTorch 词向量: datasets/vg/stanford_spilt/word2vec/GoogleNews-vectors-negative300.300d.pt
🔹 加载的词向量维度: 300
🔹 '__background__' -> '__background__' (尝试匹配)
 无法找到 '__background__' 的词向量
🔹 直接加载 PyTorch 词向量: datasets/vg/stanford_spilt/word2vec/GoogleNews-vectors-negative300.300d.pt
🔹 加载的词向量维度: 300
🔹 '__background__' -> '__background__' (尝试匹配)
 无法找到 '__background__' 的词向量
🔹 直接加载 PyTorch 词向量: datasets/vg/stanford_spilt/word2vec/GoogleNews-vectors-negative300.300d.pt
🔹 加载的词向量维度: 300
🔹 '__background__' -> '__background__' (尝试匹配)
 无法找到 '__background__' 的词向量
[03/13 14:54:04 pysgg]: #################### end model construction ####################
[03/13 14:54:04 pysgg]: GeneralizedRCNN(
  (backbone): Sequential(
    (body): ResNet(
      (stem): StemWithFixedBatchNorm(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): FrozenBatchNorm2d()
      )
      (layer1): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
      (layer2): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (3): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
      (layer3): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (3): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (4): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (5): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (6): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (7): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (8): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (9): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (10): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (11): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (12): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (13): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (14): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (15): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (16): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (17): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (18): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (19): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (20): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (21): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (22): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
      (layer4): Sequential(
        (0): BottleneckWithFixedBatchNorm(
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): FrozenBatchNorm2d()
          )
          (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (1): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
        (2): BottleneckWithFixedBatchNorm(
          (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): FrozenBatchNorm2d()
          (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (bn2): FrozenBatchNorm2d()
          (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): FrozenBatchNorm2d()
        )
      )
    )
    (fpn): FPN(
      (fpn_inner1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_inner4): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_layer4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (top_blocks): LastLevelMaxPool()
    )
  )
  (rpn): RPNModule(
    (anchor_generator): AnchorGenerator(
      (cell_anchors): BufferList()
    )
    (head): RPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cls_logits): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
      (bbox_pred): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))
    )
    (box_selector_train): RPNPostProcessor()
    (box_selector_test): RPNPostProcessor()
  )
  (roi_heads): CombinedROIHeads(
    (box): ROIBoxHead(
      (feature_extractor): FPN2MLPFeatureExtractor(
        (pooler): Pooler(
          (poolers): ModuleList(
            (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2)
            (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2)
            (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2)
            (3): ROIAlign(output_size=(7, 7), spatial_scale=0.3125, sampling_ratio=2)
          )
        )
        (fc6): Linear(in_features=12544, out_features=4096, bias=True)
        (fc7): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (predictor): FPNPredictor(
        (cls_score): Linear(in_features=4096, out_features=151, bias=True)
        (bbox_pred): Linear(in_features=4096, out_features=604, bias=True)
      )
      (post_processor): PostProcessor()
    )
    (relation): ROIRelationHead(
      (union_feature_extractor): RelationFeatureExtractor(
        (feature_extractor): FPN2MLPFeatureExtractor(
          (pooler): Pooler(
            (poolers): ModuleList(
              (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2)
              (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2)
              (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2)
              (3): ROIAlign(output_size=(7, 7), spatial_scale=0.3125, sampling_ratio=2)
            )
            (reduce_channel): Sequential(
              (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
            )
          )
          (fc6): Linear(in_features=12544, out_features=4096, bias=True)
          (fc7): Linear(in_features=4096, out_features=4096, bias=True)
        )
        (rect_conv): Sequential(
          (0): Conv2d(2, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
          (1): ReLU(inplace=True)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
          (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (5): ReLU(inplace=True)
          (6): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (box_feature_extractor): FPN2MLPFeatureExtractor(
        (pooler): Pooler(
          (poolers): ModuleList(
            (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2)
            (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2)
            (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2)
            (3): ROIAlign(output_size=(7, 7), spatial_scale=0.3125, sampling_ratio=2)
          )
        )
        (fc6): Linear(in_features=12544, out_features=4096, bias=True)
        (fc7): Linear(in_features=4096, out_features=4096, bias=True)
      )
      (predictor): BGNNPredictor(
        (context_layer): BGNNContext(
          (pairwise_feature_extractor): PairwiseFeatureExtractor(
            (obj_embed_on_prob_dist): Embedding(151, 300)
            (obj_embed_on_pred_label): Embedding(151, 300)
            (rel_feature_up_dim): Linear(in_features=4096, out_features=2048, bias=True)
            (pairwise_obj_feat_updim_fc): Linear(in_features=4908, out_features=1024, bias=True)
            (pos_embed): Sequential(
              (0): Linear(in_features=9, out_features=32, bias=True)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)
              (2): Linear(in_features=32, out_features=128, bias=True)
              (3): ReLU(inplace=True)
            )
            (spt_emb): Sequential(
              (0): Linear(in_features=32, out_features=512, bias=True)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=1024, bias=True)
              (3): ReLU(inplace=True)
            )
            (pairwise_rel_feat_finalize_fc): Sequential(
              (0): Linear(in_features=1024, out_features=2048, bias=True)
              (1): ReLU(inplace=True)
            )
            (obj_hidden_linear): Linear(in_features=4524, out_features=512, bias=True)
            (obj_feat_aug_finalize_fc): Sequential(
              (0): Linear(in_features=4908, out_features=2048, bias=True)
              (1): ReLU(inplace=True)
            )
          )
          (relation_conf_aware_models): ModuleList(
            (0): RelAwareRelFeature(
              (obj_sem_embed): Embedding(151, 300)
              (obj_pos_embed): Sequential(
                (0): Linear(in_features=9, out_features=128, bias=True)
                (1): ReLU()
                (2): Linear(in_features=128, out_features=128, bias=True)
              )
              (proposal_box_feat_extract): Sequential(
                (0): ReLU()
                (1): Linear(in_features=856, out_features=512, bias=True)
              )
              (vis_embed): Sequential(
                (0): ReLU()
                (1): Linear(in_features=2048, out_features=512, bias=True)
              )
              (proposal_feat_fusion): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=512, bias=True)
              )
              (proposal_relness_cls_fc): Sequential(
                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=50, bias=True)
              )
              (fusion_layer): Linear(in_features=50, out_features=1, bias=True)
            )
            (1): RelAwareRelFeature(
              (obj_sem_embed): Embedding(151, 300)
              (obj_pos_embed): Sequential(
                (0): Linear(in_features=9, out_features=128, bias=True)
                (1): ReLU()
                (2): Linear(in_features=128, out_features=128, bias=True)
              )
              (proposal_box_feat_extract): Sequential(
                (0): ReLU()
                (1): Linear(in_features=856, out_features=512, bias=True)
              )
              (vis_embed): Sequential(
                (0): ReLU()
                (1): Linear(in_features=512, out_features=512, bias=True)
              )
              (proposal_feat_fusion): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=512, bias=True)
              )
              (proposal_relness_cls_fc): Sequential(
                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=50, bias=True)
              )
              (fusion_layer): Linear(in_features=50, out_features=1, bias=True)
            )
            (2): RelAwareRelFeature(
              (obj_sem_embed): Embedding(151, 300)
              (obj_pos_embed): Sequential(
                (0): Linear(in_features=9, out_features=128, bias=True)
                (1): ReLU()
                (2): Linear(in_features=128, out_features=128, bias=True)
              )
              (proposal_box_feat_extract): Sequential(
                (0): ReLU()
                (1): Linear(in_features=856, out_features=512, bias=True)
              )
              (vis_embed): Sequential(
                (0): ReLU()
                (1): Linear(in_features=512, out_features=512, bias=True)
              )
              (proposal_feat_fusion): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=512, bias=True)
              )
              (proposal_relness_cls_fc): Sequential(
                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=50, bias=True)
              )
              (fusion_layer): Linear(in_features=50, out_features=1, bias=True)
            )
          )
          (learnable_relness_score_gating_recalibration): LearnableRelatednessGating()
          (obj_downdim_fc): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
            (1): ReLU(inplace=True)
          )
          (rel_downdim_fc): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
            (1): ReLU(inplace=True)
          )
          (obj_pair2rel_fuse): Sequential(
            (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): Linear(in_features=1024, out_features=512, bias=True)
            (2): ReLU()
          )
          (gate_sub2pred): Sequential(
            (0): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (1): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (2): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
          )
          (gate_obj2pred): Sequential(
            (0): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (1): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (2): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
          )
          (gate_pred2sub): Sequential(
            (0): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (1): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (2): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
          )
          (gate_pred2obj): Sequential(
            (0): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (1): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
            (2): MessagePassingUnit_v1(
              (w): Sequential(
                (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (1): ReLU()
                (2): Linear(in_features=1024, out_features=128, bias=True)
              )
            )
          )
          (object_msg_fusion): Sequential(
            (0): MessageFusion(
              (wih): Linear(in_features=512, out_features=512, bias=True)
              (whh): Linear(in_features=512, out_features=512, bias=True)
            )
            (1): MessageFusion(
              (wih): Linear(in_features=512, out_features=512, bias=True)
              (whh): Linear(in_features=512, out_features=512, bias=True)
            )
            (2): MessageFusion(
              (wih): Linear(in_features=512, out_features=512, bias=True)
              (whh): Linear(in_features=512, out_features=512, bias=True)
            )
          )
          (pred_msg_fusion): Sequential(
            (0): MessageFusion(
              (wih): Linear(in_features=512, out_features=512, bias=True)
              (whh): Linear(in_features=512, out_features=512, bias=True)
            )
            (1): MessageFusion(
              (wih): Linear(in_features=512, out_features=512, bias=True)
              (whh): Linear(in_features=512, out_features=512, bias=True)
            )
            (2): MessageFusion(
              (wih): Linear(in_features=512, out_features=512, bias=True)
              (whh): Linear(in_features=512, out_features=512, bias=True)
            )
          )
        )
        (rel_classifier): DotProductClassifier()
        (obj_classifier): DotProductClassifier()
        (rel_aware_loss_eval): RelAwareLoss()
        (freq_bias): FrequencyBias(
          (obj_baseline): Embedding(22801, 51)
        )
      )
      (post_processor): PostProcessor_Relation()
    )
  )
)
[03/13 14:54:04 pysgg]: trainable models:
[03/13 14:54:04 pysgg]: 
backbone.body.stem.conv1.weight                                                 : [64,3,7,7]      (    9408) (    )
backbone.body.layer1.0.downsample.0.weight                                      : [256,64,1,1]    (   16384) (    )
backbone.body.layer1.0.conv1.weight                                             : [256,64,1,1]    (   16384) (    )
backbone.body.layer1.0.conv2.weight                                             : [256,8,3,3]     (   18432) (    )
backbone.body.layer1.0.conv3.weight                                             : [256,256,1,1]   (   65536) (    )
backbone.body.layer1.1.conv1.weight                                             : [256,256,1,1]   (   65536) (    )
backbone.body.layer1.1.conv2.weight                                             : [256,8,3,3]     (   18432) (    )
backbone.body.layer1.1.conv3.weight                                             : [256,256,1,1]   (   65536) (    )
backbone.body.layer1.2.conv1.weight                                             : [256,256,1,1]   (   65536) (    )
backbone.body.layer1.2.conv2.weight                                             : [256,8,3,3]     (   18432) (    )
backbone.body.layer1.2.conv3.weight                                             : [256,256,1,1]   (   65536) (    )
backbone.body.layer2.0.downsample.0.weight                                      : [512,256,1,1]   (  131072) (    )
backbone.body.layer2.0.conv1.weight                                             : [512,256,1,1]   (  131072) (    )
backbone.body.layer2.0.conv2.weight                                             : [512,16,3,3]    (   73728) (    )
backbone.body.layer2.0.conv3.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer2.1.conv1.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer2.1.conv2.weight                                             : [512,16,3,3]    (   73728) (    )
backbone.body.layer2.1.conv3.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer2.2.conv1.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer2.2.conv2.weight                                             : [512,16,3,3]    (   73728) (    )
backbone.body.layer2.2.conv3.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer2.3.conv1.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer2.3.conv2.weight                                             : [512,16,3,3]    (   73728) (    )
backbone.body.layer2.3.conv3.weight                                             : [512,512,1,1]   (  262144) (    )
backbone.body.layer3.0.downsample.0.weight                                      : [1024,512,1,1]  (  524288) (    )
backbone.body.layer3.0.conv1.weight                                             : [1024,512,1,1]  (  524288) (    )
backbone.body.layer3.0.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.0.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.1.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.1.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.1.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.2.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.2.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.2.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.3.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.3.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.3.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.4.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.4.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.4.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.5.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.5.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.5.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.6.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.6.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.6.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.7.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.7.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.7.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.8.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.8.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.8.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.9.conv1.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.9.conv2.weight                                             : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.9.conv3.weight                                             : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.10.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.10.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.10.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.11.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.11.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.11.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.12.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.12.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.12.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.13.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.13.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.13.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.14.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.14.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.14.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.15.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.15.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.15.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.16.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.16.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.16.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.17.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.17.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.17.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.18.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.18.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.18.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.19.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.19.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.19.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.20.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.20.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.20.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.21.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.21.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.21.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.22.conv1.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer3.22.conv2.weight                                            : [1024,32,3,3]   (  294912) (    )
backbone.body.layer3.22.conv3.weight                                            : [1024,1024,1,1] ( 1048576) (    )
backbone.body.layer4.0.downsample.0.weight                                      : [2048,1024,1,1] ( 2097152) (    )
backbone.body.layer4.0.conv1.weight                                             : [2048,1024,1,1] ( 2097152) (    )
backbone.body.layer4.0.conv2.weight                                             : [2048,64,3,3]   ( 1179648) (    )
backbone.body.layer4.0.conv3.weight                                             : [2048,2048,1,1] ( 4194304) (    )
backbone.body.layer4.1.conv1.weight                                             : [2048,2048,1,1] ( 4194304) (    )
backbone.body.layer4.1.conv2.weight                                             : [2048,64,3,3]   ( 1179648) (    )
backbone.body.layer4.1.conv3.weight                                             : [2048,2048,1,1] ( 4194304) (    )
backbone.body.layer4.2.conv1.weight                                             : [2048,2048,1,1] ( 4194304) (    )
backbone.body.layer4.2.conv2.weight                                             : [2048,64,3,3]   ( 1179648) (    )
backbone.body.layer4.2.conv3.weight                                             : [2048,2048,1,1] ( 4194304) (    )
backbone.fpn.fpn_inner1.weight                                                  : [256,256,1,1]   (   65536) (    )
backbone.fpn.fpn_layer1.weight                                                  : [256,256,3,3]   (  589824) (    )
backbone.fpn.fpn_inner2.weight                                                  : [256,512,1,1]   (  131072) (    )
backbone.fpn.fpn_layer2.weight                                                  : [256,256,3,3]   (  589824) (    )
backbone.fpn.fpn_inner3.weight                                                  : [256,1024,1,1]  (  262144) (    )
backbone.fpn.fpn_layer3.weight                                                  : [256,256,3,3]   (  589824) (    )
backbone.fpn.fpn_inner4.weight                                                  : [256,2048,1,1]  (  524288) (    )
backbone.fpn.fpn_layer4.weight                                                  : [256,256,3,3]   (  589824) (    )
rpn.head.conv.weight                                                            : [256,256,3,3]   (  589824) (    )
rpn.head.cls_logits.weight                                                      : [4,256,1,1]     (    1024) (    )
rpn.head.bbox_pred.weight                                                       : [16,256,1,1]    (    4096) (    )
roi_heads.box.feature_extractor.fc6.weight                                      : [4096,12544]    (51380224) (    )
roi_heads.box.feature_extractor.fc7.weight                                      : [4096,4096]     (16777216) (    )
roi_heads.box.predictor.cls_score.weight                                        : [151,4096]      (  618496) (    )
roi_heads.box.predictor.bbox_pred.weight                                        : [604,4096]      ( 2473984) (    )
roi_heads.relation.rel_pn_thres                                                 : [1]             (       1) (    )
roi_heads.relation.rel_pn_thres_for_test                                        : [1]             (       1) (    )
roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: [256,1024,3,3]  ( 2359296) (grad)
roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight         : [4096,12544]    (51380224) (grad)
roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight         : [4096,4096]     (16777216) (grad)
roi_heads.relation.union_feature_extractor.rect_conv.0.weight                   : [128,2,7,7]     (   12544) (grad)
roi_heads.relation.union_feature_extractor.rect_conv.2.weight                   : [128]           (     128) (grad)
roi_heads.relation.union_feature_extractor.rect_conv.4.weight                   : [256,128,3,3]   (  294912) (grad)
roi_heads.relation.union_feature_extractor.rect_conv.6.weight                   : [256]           (     256) (grad)
roi_heads.relation.box_feature_extractor.fc6.weight                             : [4096,12544]    (51380224) (grad)
roi_heads.relation.box_feature_extractor.fc7.weight                             : [4096,4096]     (16777216) (grad)
roi_heads.relation.predictor.freq_lambda                                        : [1]             (       1) (    )
roi_heads.relation.predictor.context_layer.padding_feature                      : [512]           (     512) (    )
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_embed_on_prob_dist.weight: [151,300]       (   45300) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_embed_on_pred_label.weight: [151,300]       (   45300) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.rel_feature_up_dim.weight: [2048,4096]     ( 8388608) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_obj_feat_updim_fc.weight: [1024,4908]     ( 5025792) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.0.weight: [32,9]          (     288) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.weight: [32]            (      32) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.2.weight: [128,32]        (    4096) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.0.weight: [512,32]        (   16384) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.2.weight: [1024,512]      (  524288) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_rel_feat_finalize_fc.0.weight: [2048,1024]     ( 2097152) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_hidden_linear.weight: [512,4524]      ( 2316288) (grad)
roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_feat_aug_finalize_fc.0.weight: [2048,4908]     (10051584) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_sem_embed.weight: [151,300]       (   45300) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.0.weight: [128,9]         (    1152) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.2.weight: [128,128]       (   16384) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_box_feat_extract.1.weight: [512,856]       (  438272) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.vis_embed.1.weight: [512,2048]      ( 1048576) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.0.weight: [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.2.weight: [512,1024]      (  524288) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.0.weight: [512]           (     512) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.2.weight: [50,512]        (   25600) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.fusion_layer.weight: [1,50]          (      50) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_sem_embed.weight: [151,300]       (   45300) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.0.weight: [128,9]         (    1152) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.2.weight: [128,128]       (   16384) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_box_feat_extract.1.weight: [512,856]       (  438272) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.vis_embed.1.weight: [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.0.weight: [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.2.weight: [512,1024]      (  524288) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.0.weight: [512]           (     512) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.2.weight: [50,512]        (   25600) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.fusion_layer.weight: [1,50]          (      50) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_sem_embed.weight: [151,300]       (   45300) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.0.weight: [128,9]         (    1152) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.2.weight: [128,128]       (   16384) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_box_feat_extract.1.weight: [512,856]       (  438272) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.vis_embed.1.weight: [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.0.weight: [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.2.weight: [512,1024]      (  524288) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.0.weight: [512]           (     512) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.2.weight: [50,512]        (   25600) (grad)
roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.fusion_layer.weight: [1,50]          (      50) (grad)
roi_heads.relation.predictor.context_layer.learnable_relness_score_gating_recalibration.alpha: [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.learnable_relness_score_gating_recalibration.beta: [1]             (       1) (    )
roi_heads.relation.predictor.context_layer.obj_downdim_fc.0.weight              : [512,2048]      ( 1048576) (grad)
roi_heads.relation.predictor.context_layer.rel_downdim_fc.0.weight              : [512,2048]      ( 1048576) (grad)
roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.1.weight           : [512,1024]      (  524288) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.0.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.0.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.0.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.0.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.1.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.1.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.1.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.1.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.2.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.2.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.2.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_sub2pred.2.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.0.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.0.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.0.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.0.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.1.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.1.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.1.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.1.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.2.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.2.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.2.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_obj2pred.2.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.0.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.0.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.0.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.0.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.1.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.1.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.1.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.1.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.2.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.2.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.2.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2sub.2.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.0.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.0.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.0.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.0.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.1.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.1.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.1.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.1.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.2.gate_weight          : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.2.aux_gate_weight      : [1]             (       1) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.2.w.0.weight           : [1024]          (    1024) (grad)
roi_heads.relation.predictor.context_layer.gate_pred2obj.2.w.2.weight           : [128,1024]      (  131072) (grad)
roi_heads.relation.predictor.context_layer.object_msg_fusion.0.wih.weight       : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.object_msg_fusion.0.whh.weight       : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.object_msg_fusion.1.wih.weight       : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.object_msg_fusion.1.whh.weight       : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.object_msg_fusion.2.wih.weight       : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.object_msg_fusion.2.whh.weight       : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.pred_msg_fusion.0.wih.weight         : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.pred_msg_fusion.0.whh.weight         : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.pred_msg_fusion.1.wih.weight         : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.pred_msg_fusion.1.whh.weight         : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.pred_msg_fusion.2.wih.weight         : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.context_layer.pred_msg_fusion.2.whh.weight         : [512,512]       (  262144) (grad)
roi_heads.relation.predictor.rel_classifier.weight                              : [51,512]        (   26112) (grad)
roi_heads.relation.predictor.obj_classifier.weight                              : [151,512]       (   77312) (grad)
roi_heads.relation.predictor.freq_bias.obj_baseline.weight                      : [22801,51]      ( 1162851) (grad)
 ----- 
 
      trainable parameters:  180.907/342.646 M 
 
load model to GPU
[03/13 14:54:35 pysgg]: #################### end optimizer and shcedule ####################
[03/13 14:54:35 utils.checkpoint]: Loading parameters from checkpoints/detection/pretrained_faster_rcnn/vg_faster_det.pth
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.box_feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.box_feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.box_feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.box_feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to roi_heads.box.feature_extractor.fc6.bias in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to roi_heads.box.feature_extractor.fc6.weight in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to roi_heads.box.feature_extractor.fc7.bias in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to roi_heads.box.feature_extractor.fc7.weight in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
[03/13 14:54:36 utils.model_serialization]: MAPPING roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.bias                                                            loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.box_feature_extractor.fc6.weight                                                          loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.bias                                                            loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.box_feature_extractor.fc7.weight                                                          loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.0.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.0.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.0.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.0.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.0.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.0.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.1.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.1.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.1.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.1.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.1.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.1.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.2.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.2.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.2.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.2.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.2.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_obj2pred.2.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.0.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.0.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.0.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.0.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.0.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.0.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.1.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.1.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.1.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.1.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.1.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.1.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.2.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.2.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.2.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.2.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.2.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2obj.2.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.0.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.0.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.0.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.0.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.0.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.0.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.1.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.1.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.1.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.1.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.1.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.1.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.2.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.2.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.2.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.2.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.2.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_pred2sub.2.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.0.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.0.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.0.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.0.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.0.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.0.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.1.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.1.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.1.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.1.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.1.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.1.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.2.aux_gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.2.gate_weight of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.2.w.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.2.w.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.2.w.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.gate_sub2pred.2.w.2.weight of shape (128, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.learnable_relness_score_gating_recalibration.alpha of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.learnable_relness_score_gating_recalibration.beta of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_downdim_fc.0.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_downdim_fc.0.weight of shape (512, 2048)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.0.num_batches_tracked of shape ()
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.0.running_mean of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.0.running_var of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.obj_pair2rel_fuse.1.weight of shape (512, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.0.whh.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.0.whh.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.0.wih.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.0.wih.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.1.whh.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.1.whh.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.1.wih.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.1.wih.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.2.whh.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.2.whh.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.2.wih.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.object_msg_fusion.2.wih.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.padding_feature of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_embed_on_pred_label.weight of shape (151, 300)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_embed_on_prob_dist.weight of shape (151, 300)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_feat_aug_finalize_fc.0.bias of shape (2048,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_feat_aug_finalize_fc.0.weight of shape (2048, 4908)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_hidden_linear.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_hidden_linear.weight of shape (512, 4524)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_obj_feat_updim_fc.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_obj_feat_updim_fc.weight of shape (1024, 4908)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_rel_feat_finalize_fc.0.bias of shape (2048,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_rel_feat_finalize_fc.0.weight of shape (2048, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.0.bias of shape (32,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.0.weight of shape (32, 9)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.bias of shape (32,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.num_batches_tracked of shape ()
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.running_mean of shape (32,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.running_var of shape (32,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.weight of shape (32,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.2.weight of shape (128, 32)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.rel_feature_up_dim.bias of shape (2048,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.rel_feature_up_dim.weight of shape (2048, 4096)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.0.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.0.weight of shape (512, 32)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.2.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.2.weight of shape (1024, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.0.whh.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.0.whh.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.0.wih.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.0.wih.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.1.whh.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.1.whh.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.1.wih.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.1.wih.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.2.whh.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.2.whh.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.2.wih.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.pred_msg_fusion.2.wih.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.rel_downdim_fc.0.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.rel_downdim_fc.0.weight of shape (512, 2048)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.fusion_layer.bias of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.fusion_layer.weight of shape (1, 50)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.0.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.0.weight of shape (128, 9)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.2.weight of shape (128, 128)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_sem_embed.weight of shape (151, 300)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_box_feat_extract.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_box_feat_extract.1.weight of shape (512, 856)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.2.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.2.weight of shape (512, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.0.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.0.weight of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.2.bias of shape (50,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.2.weight of shape (50, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.vis_embed.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.vis_embed.1.weight of shape (512, 2048)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.fusion_layer.bias of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.fusion_layer.weight of shape (1, 50)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.0.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.0.weight of shape (128, 9)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.2.weight of shape (128, 128)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_sem_embed.weight of shape (151, 300)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_box_feat_extract.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_box_feat_extract.1.weight of shape (512, 856)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.2.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.2.weight of shape (512, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.0.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.0.weight of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.2.bias of shape (50,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.2.weight of shape (50, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.vis_embed.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.vis_embed.1.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.fusion_layer.bias of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.fusion_layer.weight of shape (1, 50)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.0.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.0.weight of shape (128, 9)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.2.weight of shape (128, 128)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_sem_embed.weight of shape (151, 300)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_box_feat_extract.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_box_feat_extract.1.weight of shape (512, 856)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.0.bias of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.0.weight of shape (1024,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.2.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.2.weight of shape (512, 1024)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.0.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.0.weight of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.2.bias of shape (50,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.2.weight of shape (50, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.vis_embed.1.bias of shape (512,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.vis_embed.1.weight of shape (512, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.freq_lambda of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.obj_classifier.bias of shape (151,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.obj_classifier.weight of shape (151, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.rel_classifier.bias of shape (51,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.predictor.rel_classifier.weight of shape (51, 512)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.rel_pn_thres of shape (1,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.rel_pn_thres_for_test of shape (1,)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                                        loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                                      loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                                        loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
[03/13 14:54:36 utils.model_serialization]: REMATCHING! roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                                      loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
[03/13 14:54:36 utils.model_serialization]: NO-MATCHING of current module: roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
[03/13 14:54:36 pysgg]: #################### end distributed ####################
[03/13 14:54:36 pysgg]: Start preclser_relpn_pretrain
[03/13 14:54:36 pysgg]: Start training
/home/p_zhuzy/miniconda3/envs/pysgg/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/p_zhuzy/miniconda3/envs/pysgg/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[03/13 14:54:48 pysgg]: ---Total norm inf clip coef 0.00000-----------------
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 5624.407227, (torch.Size([256, 1024, 3, 3]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 91.400833, (torch.Size([256]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 22581.125000, (torch.Size([4096, 12544]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 119.827446, (torch.Size([4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 22036.529297, (torch.Size([4096, 4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 263.315002, (torch.Size([4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 1120.067993, (torch.Size([128, 2, 7, 7]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 158.690109, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 60.173477, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 40.059795, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 3602.115967, (torch.Size([256, 128, 3, 3]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 54.129646, (torch.Size([256]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 52.659245, (torch.Size([256]))
[03/13 14:54:48 pysgg]: roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 172.327911, (torch.Size([256]))
[03/13 14:54:48 pysgg]: roi_heads.relation.box_feature_extractor.fc6.weight: 0.000000, (torch.Size([4096, 12544]))
[03/13 14:54:48 pysgg]: roi_heads.relation.box_feature_extractor.fc6.bias : 27.730738, (torch.Size([4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.box_feature_extractor.fc7.weight: 11.251529, (torch.Size([4096, 4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.box_feature_extractor.fc7.bias : 54.699654, (torch.Size([4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_embed_on_prob_dist.weight: 0.524527, (torch.Size([151, 300]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_embed_on_pred_label.weight: 15.443213, (torch.Size([151, 300]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.rel_feature_up_dim.weight: 13609.500977, (torch.Size([2048, 4096]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.rel_feature_up_dim.bias: 1218.389648, (torch.Size([2048]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_obj_feat_updim_fc.weight: 198.789154, (torch.Size([1024, 4908]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_obj_feat_updim_fc.bias: 59.826969, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.0.weight: 4.811677, (torch.Size([32, 9]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.0.bias: 0.000794, (torch.Size([32]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.weight: 1.443916, (torch.Size([32]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.1.bias: 1.603606, (torch.Size([32]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.2.weight: 6.950645, (torch.Size([128, 32]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pos_embed.2.bias: 1.691105, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.0.weight: 40.170818, (torch.Size([512, 32]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.0.bias: 12.835624, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.2.weight: 70.780769, (torch.Size([1024, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.spt_emb.2.bias: 22.791824, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_rel_feat_finalize_fc.0.weight: 89.229210, (torch.Size([2048, 1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.pairwise_rel_feat_finalize_fc.0.bias: 719.585876, (torch.Size([2048]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_hidden_linear.weight: 124.817833, (torch.Size([512, 4524]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.pairwise_feature_extractor.obj_hidden_linear.bias: 19.531841, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_sem_embed.weight: 16507.369141, (torch.Size([151, 300]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.0.weight: 53526.960938, (torch.Size([128, 9]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.0.bias: 39695.566406, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.2.weight: 253873.203125, (torch.Size([128, 128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.obj_pos_embed.2.bias: 109141.531250, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_box_feat_extract.1.weight: 1162756.875000, (torch.Size([512, 856]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_box_feat_extract.1.bias: inf, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.vis_embed.1.weight: 3324952.500000, (torch.Size([512, 2048]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.vis_embed.1.bias: inf, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.0.weight: 59802.851562, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.0.bias: 66554.007812, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.2.weight: inf, (torch.Size([512, 1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_feat_fusion.2.bias: 178949.328125, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.0.weight: 81544.062500, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.0.bias: 72667.070312, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.2.weight: inf, (torch.Size([50, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.proposal_relness_cls_fc.2.bias: 224672.062500, (torch.Size([50]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.fusion_layer.weight: inf, (torch.Size([1, 50]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.0.fusion_layer.bias: inf, (torch.Size([1]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_sem_embed.weight: 18692.148438, (torch.Size([151, 300]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.0.weight: 47639.613281, (torch.Size([128, 9]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.0.bias: 37366.511719, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.2.weight: 275266.968750, (torch.Size([128, 128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.obj_pos_embed.2.bias: 105341.000000, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_box_feat_extract.1.weight: 1249487.625000, (torch.Size([512, 856]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_box_feat_extract.1.bias: inf, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.vis_embed.1.weight: 1879684.250000, (torch.Size([512, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.vis_embed.1.bias: inf, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.0.weight: 71346.976562, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.0.bias: 72492.617188, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.2.weight: inf, (torch.Size([512, 1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_feat_fusion.2.bias: 189785.328125, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.0.weight: 74295.570312, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.0.bias: 76808.617188, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.2.weight: inf, (torch.Size([50, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.proposal_relness_cls_fc.2.bias: 232503.046875, (torch.Size([50]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.fusion_layer.weight: inf, (torch.Size([1, 50]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.1.fusion_layer.bias: inf, (torch.Size([1]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_sem_embed.weight: 25962.109375, (torch.Size([151, 300]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.0.weight: 86240.937500, (torch.Size([128, 9]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.0.bias: 65693.820312, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.2.weight: 400362.625000, (torch.Size([128, 128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.obj_pos_embed.2.bias: 190874.500000, (torch.Size([128]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_box_feat_extract.1.weight: 1616413.125000, (torch.Size([512, 856]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_box_feat_extract.1.bias: inf, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.vis_embed.1.weight: inf, (torch.Size([512, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.vis_embed.1.bias: inf, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.0.weight: 91332.906250, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.0.bias: 98306.460938, (torch.Size([1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.2.weight: inf, (torch.Size([512, 1024]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_feat_fusion.2.bias: 255747.015625, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.0.weight: 113078.703125, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.0.bias: 105573.921875, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.2.weight: inf, (torch.Size([50, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.proposal_relness_cls_fc.2.bias: inf, (torch.Size([50]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.fusion_layer.weight: inf, (torch.Size([1, 50]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.relation_conf_aware_models.2.fusion_layer.bias: inf, (torch.Size([1]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.rel_downdim_fc.0.weight: 11474.031250, (torch.Size([512, 2048]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.context_layer.rel_downdim_fc.0.bias: 1234.394775, (torch.Size([512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.rel_classifier.weight: 13780.130859, (torch.Size([51, 512]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.rel_classifier.bias  : 3733.860840, (torch.Size([51]))
[03/13 14:54:48 pysgg]: roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 3733.101807, (torch.Size([22801, 51]))
[03/13 14:54:48 pysgg]: -------------------------------
[03/13 14:55:51 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:01:14
  eta: 0:11:12
  iter: 100/1000
  loss: 5.5318 (7.6102)
  loss_rel: 0.1518 (0.1871)
  pre_rel_classify_loss_iter-0: 1.3117 (1.9491)
  pre_rel_classify_loss_iter-1: 1.6008 (2.3630)
  pre_rel_classify_loss_iter-2: 2.3085 (3.1111)
  time: 0.4351 (0.7474)
  data: 0.0056 (0.0413)
  lr: 0.008960
  max mem: 19712

[03/13 14:55:51 pysgg]: relness module pretraining..
[03/13 14:56:40 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:02:03
  eta: 0:08:15
  iter: 200/1000
  loss: 2.6470 (6.0401)
  loss_rel: 0.1502 (0.1916)
  pre_rel_classify_loss_iter-0: 0.5681 (1.5138)
  pre_rel_classify_loss_iter-1: 0.8645 (1.8966)
  pre_rel_classify_loss_iter-2: 1.0410 (2.4381)
  time: 0.3907 (0.6188)
  data: 0.0056 (0.0236)
  lr: 0.014720
  max mem: 19712

[03/13 14:56:40 pysgg]: relness module pretraining..
[03/13 14:57:28 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:02:52
  eta: 0:06:41
  iter: 300/1000
  loss: 1.1647 (4.7312)
  loss_rel: 0.2080 (0.1950)
  pre_rel_classify_loss_iter-0: 0.2588 (1.1751)
  pre_rel_classify_loss_iter-1: 0.2945 (1.4854)
  pre_rel_classify_loss_iter-2: 0.3124 (1.8757)
  time: 0.3960 (0.5741)
  data: 0.0056 (0.0176)
  lr: 0.020480
  max mem: 19712

[03/13 14:57:28 pysgg]: relness module pretraining..
[03/13 14:58:14 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:03:37
  eta: 0:05:26
  iter: 400/1000
  loss: 1.0935 (3.8365)
  loss_rel: 0.1502 (0.1925)
  pre_rel_classify_loss_iter-0: 0.2870 (0.9556)
  pre_rel_classify_loss_iter-1: 0.3117 (1.1979)
  pre_rel_classify_loss_iter-2: 0.3111 (1.4905)
  time: 0.3804 (0.5438)
  data: 0.0056 (0.0147)
  lr: 0.026240
  max mem: 19712

[03/13 14:58:14 pysgg]: relness module pretraining..
[03/13 14:58:57 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:04:21
  eta: 0:04:21
  iter: 500/1000
  loss: 0.9764 (3.2869)
  loss_rel: 0.1580 (0.1908)
  pre_rel_classify_loss_iter-0: 0.2385 (0.8211)
  pre_rel_classify_loss_iter-1: 0.2762 (1.0209)
  pre_rel_classify_loss_iter-2: 0.2811 (1.2541)
  time: 0.3871 (0.5224)
  data: 0.0056 (0.0129)
  lr: 0.032000
  max mem: 19712

[03/13 14:58:57 pysgg]: relness module pretraining..
[03/13 14:58:57 utils.checkpoint]: Saving checkpoint to checkpoints/sgdet-BGNNPredictor/2025-03-13_14/model_0000500.pth
[03/13 14:59:42 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:05:05
  eta: 0:03:23
  iter: 600/1000
  loss: 0.9777 (2.9139)
  loss_rel: 0.1462 (0.1884)
  pre_rel_classify_loss_iter-0: 0.2671 (0.7294)
  pre_rel_classify_loss_iter-1: 0.2937 (0.9009)
  pre_rel_classify_loss_iter-2: 0.2819 (1.0952)
  time: 0.3895 (0.5099)
  data: 0.0057 (0.0153)
  lr: 0.032000
  max mem: 19712

[03/13 14:59:42 pysgg]: relness module pretraining..
[03/13 15:00:26 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:05:49
  eta: 0:02:29
  iter: 700/1000
  loss: 0.9450 (2.6419)
  loss_rel: 0.1486 (0.1846)
  pre_rel_classify_loss_iter-0: 0.2351 (0.6628)
  pre_rel_classify_loss_iter-1: 0.2559 (0.8142)
  pre_rel_classify_loss_iter-2: 0.2479 (0.9803)
  time: 0.3744 (0.4995)
  data: 0.0056 (0.0139)
  lr: 0.032000
  max mem: 19712

[03/13 15:00:26 pysgg]: relness module pretraining..
[03/13 15:01:08 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:06:31
  eta: 0:01:37
  iter: 800/1000
  loss: 0.9756 (2.4352)
  loss_rel: 0.1059 (0.1836)
  pre_rel_classify_loss_iter-0: 0.2670 (0.6116)
  pre_rel_classify_loss_iter-1: 0.2945 (0.7475)
  pre_rel_classify_loss_iter-2: 0.2936 (0.8925)
  time: 0.3810 (0.4897)
  data: 0.0056 (0.0129)
  lr: 0.032000
  max mem: 19712

[03/13 15:01:08 pysgg]: relness module pretraining..
[03/13 15:01:51 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:07:14
  eta: 0:00:48
  iter: 900/1000
  loss: 0.8908 (2.2733)
  loss_rel: 0.1610 (0.1822)
  pre_rel_classify_loss_iter-0: 0.2297 (0.5717)
  pre_rel_classify_loss_iter-1: 0.2407 (0.6953)
  pre_rel_classify_loss_iter-2: 0.2372 (0.8242)
  time: 0.3894 (0.4831)
  data: 0.0057 (0.0121)
  lr: 0.032000
  max mem: 19712

[03/13 15:01:51 pysgg]: relness module pretraining..
[03/13 15:02:32 pysgg]: 
instance name: sgdet-BGNNPredictor/2025-03-13_14
elapsed time: 0:07:56
  eta: 0:00:00
  iter: 1000/1000
  loss: 0.8695 (2.1418)
  loss_rel: 0.1477 (0.1819)
  pre_rel_classify_loss_iter-0: 0.2106 (0.5387)
  pre_rel_classify_loss_iter-1: 0.2417 (0.6526)
  pre_rel_classify_loss_iter-2: 0.2322 (0.7686)
  time: 0.3716 (0.4763)
  data: 0.0060 (0.0115)
  lr: 0.032000
  max mem: 19712

[03/13 15:02:32 pysgg]: relness module pretraining..
[03/13 15:02:32 utils.checkpoint]: Saving checkpoint to checkpoints/sgdet-BGNNPredictor/2025-03-13_14/model_0001000.pth
[03/13 15:02:34 utils.checkpoint]: Saving checkpoint to checkpoints/sgdet-BGNNPredictor/2025-03-13_14/model_final.pth
[03/13 15:02:37 pysgg]: Total training time: 0:08:00.800074 (0.4808 s / it)
/home/p_zhuzy/miniconda3/envs/pysgg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Traceback (most recent call last):
  File "/home/p_zhuzy/p_zhu/PySGG-main/train.py", line 561, in <module>
    main()
  File "/home/p_zhuzy/p_zhu/PySGG-main/train.py", line 555, in main
    run_test(args,model,args.distributed,logger)
  File "/home/p_zhuzy/p_zhu/PySGG-main/train.py", line 449, in run_test
    inference(
  File "/project/p_zhu/PySGG-main/util/inference.py", line 415, in inference
    dataset = data_loader.dataset
AttributeError: 'tuple' object has no attribute 'dataset'
